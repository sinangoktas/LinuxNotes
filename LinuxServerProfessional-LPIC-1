Notes on Linux Server Proffessional(LPIC-1) 


cat, touch, echo, cp, mv, rm, rm -r, ls, ls -l, mkdir 

cd target, cd .. > to up, cd ~ > to home

~/ > home

cat file1 => reading file
cat file1 file2 => concanates the files
cat file1 file2 > file3 => redirecting the output of concatination of file1 and file2 into file3
cat > file1 => a new file created
cat oldfile > newfile 
cat file1 >> file2 => appends file1 to file2 
echo 'some text' >> file => appends the text to file

less filename 
less command is used to view files instead of opening the file



---------------------------------

sudo apt-get install lxc

sudo lxc-create -t ubuntu -n lxcyn

##
# The default user is 'ubuntu' with password 'ubuntu'!
# Use the 'sudo' command to run tasks as root in the container.
##


sudo lxc-ls

sudo lxc-ls --fancy

sudo lxc-start -n lxcyn -d 

sudo lxc-stop -n lxcyn


sudo lxc-attach -n lxcyn > you can get a shell 

sudo lxc-info -n lxcyn

sudo lxc-destroy -n lxcyn


sudo apt-get install openssh-server

ssh ubuntu@10.0.x.xx > pw is "xxxxxx"



---------------------------------


lsmod | grep lp > to see if the module lp is exist
cat /pathtofile | grep word > search the file for a word


Managing and toubleshooting the boot process

Right shift key(during boot) > access grub menu
press "e" key > access text editor
press "c" or ctrl-c > access grub command line
advanced options > access recovery mode


shutdown -h now/5/3 > h stands for halt
shutdown -r now/5/3 > r stands for restart

history > command history


---------------------------------

tar -cvf /path/filename* > archives all the files in the present working directory into filename
tar -czvf /path/filename* > archives and compress all the files in the present working directory into filename
tar -xvf /path/filename.tar.gz > extracts arcive content into the present working directory

---------------------------------


ps aux > running processes

ps aux | grep processname > search for a particular processes

free > available memory

free -h > available memory in human readable format

uptime

top > list resouce hogs

kill or pkill pidOrProcessName > to shot down a process by name ... pkill will kill even the processname is missspelled 

killall processnameOrPid > will do the job nicely

-----------------------------------------------

processname & > forces a process to run in the background. You can keep working on the terminal but the process is attached to terminal

disown > to detach from terminal

disown %IndexNumber

jobs > displays the jobs by index

ps > display the process by id

ctrl-z  > interrupt and send back to background

nohup process & > will start the process in the backround and detach it from the terminal 

bg %IndexNumber or bg PID > push the job into background

fg %IndexNumber or fg PID - resume job

kill %IndexNumber or kill PID - Kill the job 




exit > exits the terminal

clear > clears the screen 

evince file.pdf > opens the pdf file1





------------------------------------------

lowering the nice value of a process increase its priority

nice value can be set between -20 and 19 - it is 0 by default

nice -10 apt-get update > setting the nice value to 10
nice --10 apt-get update > setting the nice value to -10

renice -10 -p PID > control nice value after launch > here reducing the nice level

renice does not take a dash as syntax as it is the case in nice

renice 10 -u username > edit user nice value > raising the nice level
renice -10 -g groupname > edit group nice value > reducing the nice level 

top or ps > to find out the nice values 


-------------------------------------------

vi editor

command mode(normal)
insert mode
command line mode

to exit >>>  press Esc > press colon(:) > then q or q! + Enter 
: > command line modei or <Insert>key > insert mode
<Esc>key > exit insert mode 


command line mode ops
:w(save a file)
:exit or :wq(exit vim)
:q(close vi without saving)

command mode
dw (deletes one word to the right)
d$ (delete to the end of the line)
dd (deletee entire line)
p (paste)
u (undo)
yy (copy line)
ZZ (save and exit)
h (move to the left)
l (move to the right)
j (move down)
k (move up)

---------------------------------------------

df -h > lists file systems
df -T > lists file system types
df -ih > lists free inodes
du -h > displays space usage by directory



-------------------------------------------

lsblk > device designation

cd /mnt 
sudo mkdir usb-drive > creating a mount point in the mnt director
sudo mount /dev/sdc1 usb-drive > device sdc1 is mounted to the mountpoint usb-drive

sudo umount sdc > to unmount ... umount ... not unmount 


---------------------------------

sudo chown -R ownername filename
sudo chgrp groupname filename

permission representation

r   w   x
4   2   1

for example 777 would mean all users have r, w and x rights
sudo chmod 666 filename > would take execute power from all users 

sudo chmod o-w filename > others stripped off write power on the object
sudo chmod o+w filename > others given back the write power now 

user classes > u owner, g group, o other


chmod u+s filename > gives user temporary owenership
chmod g+s filename

chmod +t directory_name > protects files or directory from change or being deleted by other users

umask > default value when a file or directory receive when it is created

umask > 0002
umask 0022 > you can reset the umask 
777(rwx rwx rwx) - 022 = 755(rwx r-x r-x)

---------------------------------------------


/bin core system executables and shells
/boot bootloader files
/dev hardware devices
/etc text-based config files
/home user home subdirectories
/lib code libraries
/media place to mount external devices
/mnt alternative location for mounting external devices
/opt program installation files
/proc pseudo file-system representing processes
/root root user's home directory
/run run time data storage 
/sbin admin binaries
/srv site-specific data
/sys system hardware info
/usr application files
/var variable data including logs 

/usr/bin non-essential global binaries
/usr/lib libraries
/usr/sbin non-essential system binaries
/usr/share shared application data
/usr/src application source code

/var/cache application cache data
/var/lib state information
/var/log system logs 
/var/mail user's mailboxes 



sudo find /etc -name *.conf  > will search the etc directory with files name ending with .conf

sudo locate filename > better solution 

sudo updatedb > updates the database of all system files 

whereis filename > locates the filename

whereis -bms filename > b: binary location m: manual files s: sourcecode 
whereis -b filename
whereis -m filename
whereis -s filename 
which program_name > will simalarly display the location of the binary of a program 
type program_name > will show how a particular program will be executed in the current environment - program execution paramiters


Linking files

Each file on a linux system is associated with an Inode. The Inode is a data structure that stores the file's attributes and disk block location. Without an inode's data you would not be able to find, much less use a file. It is possible however, for two files to actually share a single inode

You can obviously copy files from one location to another. What this does is create two identical files, each with its own inode pointing to its particular location. If you should edit either one of these files, the other one will, of course, not be affected.  From here on in, they're not related in any way. However, if you don't really want two separate files in two locations, but you just want to be able to access a single file more conveniently, then you can create a link between two locations. From that point, executing or editing the file in one location will cause the linked version to undergo the same changes. They are in effect, synced to each other. There are two types of linked files: symbolic links, which while remaining in sync with each other, maintains separate inodes, and hard links, which actually share a single inode. ps- if you delete the parent file the link version will be removed

######

ln existingfile linkfile > creating a linkfile 

Symbolic links are usually referred to as symlinks. But why should you want to do this?Knowing in advance that We'll often need this file under similar circumstances, We'll create a linked copy so we can easily access and update the link, but have it available in its up to date version in its original location. 

ln -s myfile myfile-soft > creating a symlink (files will have separate inodes. if the parent file(myfile) renamed or deleted, myfile-soft will cease existence. basically myfile-soft points to myfile then myfile points to the inode)

Creating a hard link works pretty much exact same way as a symlink, but without adding any argument to the command. 

ln myfile myfile-hard > creating a hard link (shares single inode therefore both looklike unique files, there is no way to tell the difference between them. if the parent file(myfile) renamed, myfile-hard will remain linked, if the parent deleted, myfile-hard will remain. basically myfile and myfile-hard points separately to a shared inode)


----------------------------------------------------------------

manage disk quotas

when multiple users use the same resource, you might need to limit the usage of users or groups on vim or nano

sudo quotacheck -avmug > build quota environment
sudo quotaon -av > enable quota controls 
sudo quotaoff -a > disable quota controls
sudo repquota -av > display quota status
sudo edquota -u username > edit user profile
sudo edquota -g groupname > edit group profile 



--------------------------------------------------

user=myname > create asystem variable
export user > makes the variable globally available
unset user
alias printtz="cd /etc;cat timezone"
unalias printtz
function myfunc() { ls -l &1 }
unset -f myfunc

ls | grep file && cat file > both executes to the right only the first comman succeed
ls | grep file || cat file > both executes to the right only the first comman fails
ls | grep file ; cat file > executes both in all cases

script files
filename.sh
chmod +x filename.sh > need to be executable
./filename.sh > to execute

sample file
#!/bin/bash > start with shebang line
echo "Today's date is: "
date
exit 0


read answer > read command will read the user input(string) and assign it to the variable answer. 

declare -i number > need to declare if you want to work with numbers

simple file 
echo "would you like to know the time? "
read answer
#assume we typed yes
echo answer
echo "ok, it is "
date
exit 0


simple file 
#!/bin/bash
declare -i n1
declare -i n2
declare -i total
echo "whats n1? "
read n1
echo "whats n2? "
read n2
total=n1+n2
echo "they equal " $total
exit 0


----------------


date > prints the date and time 
cd /etc;cat timezone > find out the time zone

---------------------------

Databases
mysql -u root -p
show databases
create database communications;
use communications;
show tables;

create table complaints (date DATE, email VARCHAR(20), message VARCHAR(250), response VARCHAR(250));

insert into complaints (date, email, message, response) values ("2017-07-21", "joe@cranky.com", "your product stinks", "so what?");

select * from complaints;

insert into complaints (date, email, message) values ("2017-07-21", "jojo@yahoo.com", "hello");

select * from complaints;

select * from complaints where email='joe@cranky.com';

update complaints
    -> set email='josef@cranky.com'
    -> where email='joe@cranky.com';

select * from complaints;

select * from complaints order by date; > ascending by default

select * from complaints order by date DESC;

select * from complaints order by date ASC;

create table purchases (customer int(2), item varchar(10), price int(3));

insert into purchases (customer, item, price) values ('1', 'book', '10');
insert into purchases (customer, item, price) values ('2', 'bike', '110');
insert into purchases (customer, item, price) values ('3', 'bread', '4');
insert into purchases (customer, item, price) values ('4', 'fish', '15');
insert into purchases (customer, item, price) values ('3', 'book', '12');


select * from purchases;
select item, sum(price) from purchases group by item;


create table customers (id int(2), name varchar(10));

insert into customers (id, name) values ('1', 'jay');
insert into customers (id, name) values ('2', 'ali');
insert into customers (id, name) values ('3', 'tony');
insert into customers (id, name) values ('4', 'kim');

select * from purchases, customers where purchases.customer=customers.id;

----------------------------------------------
adding a desktop to an instance on aws using vnc server

after creating a new instance (we created an ubuntu instance)
ps - make sure you add a security group for vnc - using default port 5901

ssh-in to terminal session to setup our graphic desktop

ssh -i keyfile.pem instancetype@ipaddress

"if permission denied 
sudo chmod 400 filename(keyfile.pem) 
or
sudo chmod 600 filename(keyfile.pem)"

add user which will be the owner of the vnc hosting session and assign pw
sudo useradd -m username
sudo passwd username > set password

sudo usermod -aG admin username
add the user to the admin group

switch users to make the new user our user on vnc
su username

to allow password based access to our system
sudo nano /etc/ssh/sshd_config
scroll down to password autantication and change the no value to yes

need to restart so the change can take effect
sudo service ssh restart


we are now ready to install the software that ubuntu will need to host graphic session
sudo apt-get install ubuntu-desktop

to permit graphic hosting session
sudo apt-get install vnc4server 


vncserver
to run the vnc server

set password when prompted and remember!

vncserver -kill :1
to stop the vnc server since we nedd to make change on the congig file 

ls -a 
to see the dot files

cd .vnc
we are now in .vnc directory

nano xstartup
uncomment the second and third commented lines and add 'sh' after exec in the third lines
unset SESSION_MANAGER
exec sh /etc/X11/xinit/xinitrc

vncserver 
to start the vnc back

go back to local computer and use remina remote desktop client

create a new desktop +New
name - aws
Protocol - VNC Virtual Network computing
Server - aws instance's public ipaddress plus :1
like 35.176.115.73:1
username

click connect 

provide password when prompted

you are in the gui desctop on the amazon cloud now


----------------------------------------------------


cd /home
sudo useradd -m terry
sudo passwd terry

sudo passwd terry

cat /etc/passwd | grep terry

sudo usermod -m -d /home/newdir terry
sets the new home directory of the user terry as /home/newdir

sudo usermod -c "GuestUser" terry
will add the full name for the user 'terry' as 'GuestUser'

cat /etc/passwd | grep terry
confirm the above change

sudo useradd -e terry 
sets the expiry date for the account

sudo useradd -G -m sudo Max
adding Max as admin to the group m

look into below commands
-p encrypted password management
-s specifying default shell for the user
-u os --uid specifying user id manually

sudo userdel -r terry
delete the user along with the mail spool if there is one

-e (or --expiredate) sets expiry date
-G (or --groups) add or remove group membership
-l (or --login) change login name
-L (or --lock) lock password
-U (or --unlock) unlock password


sudo chage --list Max
returns the date when Max's account expires
sudo chage -m 5 Max
minimum number of days between password changes
sudo chage -M 5 Max
change maximum number of days before a new password is required
sudo chage -W 7 Max
set the number of days before a password expires
user will receive a warning message

-m (or --create-home)
create user with home directory
-G (or --groups) 
add user to other groups
-p (0r --password)
specify an encrypted password
openssl-passwd-crypt
to generate such a password
-s (or --shell)
specified the default shell for the user
-u (or --uid)
manually specify a userid UID

man useradd 
more information

-----------------------------------------

sudo groupadd newname
sudo groupdel newname
sudo groupmod -n newername newname

/etc/passwd
this file contains basic user data like user ids
/etc/shadow
contains encrypted version of user password
/etc/group
contains information about all system groups
getent /etc/passwd
displays data directly from any of its user data files
/etc/skel
contains files you'd like to be automatically included with new user home directories

---------------------------------

locale 
will display the locale settings

timedatectl
your locale time details

tzselect
select your timezone

date
to print date and time 

/etc/timezome

/usr/share/zoneinfo

---------------------------------

System time

Hardware Clock - System Clock


sudo hwclock -r
displays the current time
sudo hwclock --hctosys
will apply the hardware time to system time 
sudo hwclock --systohc
will apply the system time to hardware timedatectl
sudo hwclock --utc
tells hardware to use the cordinated universal time 
sudo hwclock --localtime
applies the local time
sudo hwclock --set --date="7/20/17 13:10:00"
manually set the time 


sudo ntpdate or (ntpdate-debian)
manually update the time when
ntpq -pn
will display available peerers 
sudo apt install ntp
sudo service ntp status

less /etc/ntp.conf
where the settings kept

stratum 1 -stratum 15
ideally we connect to a server that is closest to a stratum0 server for lowest latency

/var/lib/ntp/ntp.drift
keeps the numeric record of the historic drift between our system and the time source

slewing
is the process of gradually adjusting the time that's not too far from the true time

stepping 
process of more quickly making that adjustments using larger steps 

insane time  
is the system time thats more than 1024 seconds off


System logging
blackbox of the system 

cd /var/log
where most log files are kept in

journalctl
can be used to read stsyem entries

/etc/systemd/journald.conf
journal behaviours can be controlled here

logger "text"
will send a text message to logger file 

logger -p lpr.alert
can specify the facility and level names

/etc/logrotate.conf
you can control log rotation

alternate logging systems 
syslog
rsyslog
syslog-ng
klogd

------------------------------------


Mail transfer systems

apt-cache search "mail transport agent" | less
apt-cache search mailutils | less

sendmail -t tony

/var/mail
where emails are stored

sudo nano /etc/aliases
you can add alias group

sudo newaliases
initialise the mail db

nano ~/.forward
creates a mail forwarder by creating a .forward file

mailq 
will display all mails thats currently pending


also practice setting up ssmtp server ans send email on terminal

--------------------------------

Printers

http://localhost:631/
browser interface for managing printers and jobs


printing from command line 

lp program draws its settings from its cups configuration and know all about your printers and its drivers

lp mytext.text
will print a file1

lpq
will display the que

lprm 545
will delete a print job

lprm -

lp -d nameOfThePrinterDriver filename
if more than ne printer on the network

cd /var/log/cups
print related logs 

cupsreject printername
will reject new jobs

cupsaccept printername 
will reopen the printer


----------------------------------------

Linux Networking

Network Addressing Protocols

IPv4
192.168.0.1
192.168.0 > defines 
1 > defines the endpoints - nodes:  1 to 254 since 0 and 255 reserved

192.168.1.1 > different subnet 
1.1 to 1.254

Netmask
255.255.255.0

CIDR
192.168.0.0/24

Netmask and CIDR tells routing software which octets are for networks and which for the individual devices

Private NAT networksallowed no direct access to the internet. Accsess is established through a public face IP. 

IPv6 addresses contain 32 bit in eight fields of hexadecimal numbers and promise a virtually unlimited number of unique addresses

TCP Networking

In the previous video we learned about how IP addresses are used to identify network devices. While those addresses do point requests in the right direction, there are still two more things you'll need to specify to ensure successful data transfers, the network protocol and network port. The network protocol defines how devices will communicate with each other, including how to establish connections, organize packets of data, and in some cases, how to compress or encrypt data. The three protocols the LPIC expects you to understand are TCP, UDP, and ICMP.

Perhaps the most common higher level protocol you will use is the Transmission Control Protocol TCP. In fact, the original Internet Protocol Suite, will often be referred to as TCP/IP. Largely because of it's built-in reliability, TCP is used to carry most web traffic, emails, and file transfers. Data is automatically broken down into small packets, transferred, and then reassembled at the target. TCP includes packet verification in its data stream deliveries.

For transfers that don't require error checking, like streaming audio and video or VOIP, the quicker and connection-less User Datagram Protocol UDP is often used, while UDP has no delivery conformation or verification, it does provide checksums.

The Internet Controlled Message Protocol, ICMP, is a very simple way for network devices to quickly exchange some basic information. The ping tool uses ICMP to check if a host is online and available for connectivity. You point ping to an IP or DNS address and it will send small packages with a request that they be echoed back. ping will immediately report its results. Network ports allow a single IP address to be used for multiple purposes. They can also be used to make it harder for unauthorized users to gain access to your resources.


There are, by accepted convention, three kinds of network ports. Well known ports, that we'll explore in a minute; ICANN registered ports that have been reserved for specific commercial protocols; and dynamic ports that are available for anyone to use on an ad hoc basis. All well known ports fall between ports one and 1,023.

Network Configuration

Now that we've discussed network addressing and transfer protocols, we'll have to learn how to configure and manage network interfaces and routes to ensure reliable connectivity. Most modern Linux distributions would do a pretty good job of automatically pointing a standard network interface device like an ethernet card to a DHCP server during the installation process. However, there will definitely be times when you'll need a non-standard connectivity profile, and for that, you're going to have to know both what to configure and how.

ifconfig
ip a
shows running interfaces

sudo ifup eth1
sudo ifdown eth1
sudo ip link set dev eth1 up
sudo ip link set dev eth1 down
these will stop or start an interface 

/etc/network/interfaces(Debian/Ubuntu)
/etc/sysconfig/network-scripts/(Fedora)
interface informations kept in these files 

ip a add 192.168.1.200/255.255.2555.0 dev eth1
to set a value for a device from the command line 

To be properly configured, a device needs an IP address and a subnet, both of which we've already discussed, but it also requires a default gateway router address so processes can find their way out of the computer and on to the wider network, and in some cases, an identifiable host name.


route
The route command will display the current system route table

sudo route add default gw 192.168.1.1
sudo ip route add default via 192.168.1.1
these for editing routing information

sudo dhclient et1 
dhclient can be used to manually establish your computer as DHCP client

/etc/hostname
this file contains your system's host name
/etc/hosts 
maps dns names and aliases to IP addresses.

/etc/nsswitch.conf
points to various kinds of configuration data


Amazon Web Services Virtual Private Clouds, VPCs: VPCs are AWS's primary networking architecture and are designed to help you effectively and securely manage all a project's compute resources. Any traffic moving within a VPC or to or from any external networks must successfully pass through a number of layers before it can reach its target, starting from the outer edge as an Internet gateway, which must be referenced by a route table before allowing anything through. Route tables in turn can be connected to individual subnets, whose access is controlled by access control lists, ACLs. Once past an ACL into a subnet, traffic will still fail to reach a computer database instance unless it's allowed by the rules of that instance's security group. And of course, as we've seen, you can further take advantage of various local security tools within an instance, which after all, is nothing more or less than a server.


Network DNS (Client side)

sudo apt install dnsutils

host gmail.com
host 10.0.3.16
dig gmail.com
these are for querying


Network Troubleshooting	

ping gmail.com (or ping IPAdress)
to check if the problem is with the connectivity

if there is a problem

ip a 
route
to find out your gateway

say your gateway is 10.0.3.1

try now
ping 10.0.3.1
if that works then the problem is probably somewhere between the router and your internet provider


traceroute google.com
tracepath google.com
to track packets along their network journey


nc -z -v google.com 80
ckecks if the port @ google.com is open
nc -z -v google.com 1-1000
ckecks a range of ports but this can take a very long time
netcat can also be used instead of nc

netstat -a | grep smtp
to confirm that sockets you need are accessible

netstat -s
shows very useful diagnostic data for each network protocol



------------------------------------------------

Linux Security

System Security

apt-cache search nameOfTheProgram
to find out if the program installed

apt-cache search netstat


sudo nano /etc/gsadow
more preffered over sudo su
this invokes toot powers only for a single command

sudo
Wheel
group for sudo users

/etc/sudoers
file ddefining sudo group powers

sudo usermod -aG sudo steve
add user to sudo group

sudo chage -M 30 ubuntu
sets password limits
can be used to force users to regularly change their passwords


Besides controlling system access, you should also regularly monitor the system itself for unusual and suspicious behavior.

chmod
find
fuser
nmap
last
w
who
lsof


However, it's unreasonable to think that you're actually going to do all these things regularly enough to make them useful. It'd be much more realistic to include them in scripts run automatically by cron that will issue notifications of anomalies.

sudo find / -type f -perm -u=s-ls
sudo find / -type f -perm -u=g-ls
search for suid or sgid

sudo fuser -v /usr/sbin/apache2
sudo fuser -v -n tcp 80
search for processes associated with files or ports

netstat 10.0.3.16
nmap 10.0.3.16
both scan network addresses for open ports

last
w
who
displays user login data

lsof -u steve 
which files are currently open and who is using them 

Network Security

































 









 



































 






















































